"""
ãƒ•ã‚§ãƒ¼ã‚º1: ã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆæ”¯æ´ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
3ã¤ã®ã‚¯ã‚¨ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³ã§æ¤œç´¢ã‚’å®Ÿè¡Œã—ã€çµæœã‚’è©³ç´°ã«å‡ºåŠ›
"""

import asyncio
import aiohttp
import sys
import traceback
from typing import List, Dict, Any, Optional, NamedTuple
from pathlib import Path
import json

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent))

from .logger_config import get_logger
from .utils import ConfigManager, BlacklistChecker
from .search_agent import BraveSearchClient, CompanyInfo, QueryGenerator, SearchAgent
from .data_loader import DataLoader, SheetConfig, create_data_loader_from_config
from .output_writer import OutputWriter, create_output_writer_from_config
from .scorer import HPScorer, create_scorer_from_config

logger = get_logger(__name__)

class QueryPattern(NamedTuple):
    """ã‚¯ã‚¨ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¡¨ã™ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    name: str
    template: str
    description: str

class Phase1QueryTester:
    """ãƒ•ã‚§ãƒ¼ã‚º1ã‚¯ã‚¨ãƒªãƒ†ã‚¹ã‚¿ãƒ¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.config_manager = ConfigManager(config)
        
        # å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆæœŸåŒ–
        self.blacklist_checker = BlacklistChecker(config)
        
        # Brave Search Client ã®åˆæœŸåŒ–
        brave_api_config = config.get('brave_api', {})
        self.brave_client = BraveSearchClient(
            api_key=brave_api_config.get('api_key'),
            results_per_query=brave_api_config.get('results_per_query', 10)
        )
        
        # Search Agent ã®åˆæœŸåŒ–
        self.search_agent = SearchAgent(self.brave_client)
        
        self.data_loader = create_data_loader_from_config(config)
        self.output_writer = create_output_writer_from_config(config)
        self.scorer = create_scorer_from_config(config, self.blacklist_checker)
        
        # ãƒ•ã‚§ãƒ¼ã‚º1ç”¨ã®3ã¤ã®ã‚¯ã‚¨ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®šç¾©
        self.query_patterns = [
            QueryPattern(
                name="åŸºæœ¬æƒ…å ±çµ„ã¿åˆã‚ã›",
                template="{company_name} {prefecture} {industry}",
                description="ä¼æ¥­åã€éƒ½é“åºœçœŒã€æ¥­ç¨®ã®çµ„ã¿åˆã‚ã›"
            ),
            QueryPattern(
                name="å…¬å¼ã‚µã‚¤ãƒˆæŒ‡å®š", 
                template="{company_name} å…¬å¼ã‚µã‚¤ãƒˆ",
                description="ä¼æ¥­å + å…¬å¼ã‚µã‚¤ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"
            ),
            QueryPattern(
                name="ãƒ‰ãƒ¡ã‚¤ãƒ³é™å®šæ¤œç´¢",
                template="\"{company_name}\" site:.co.jp OR site:.com",
                description="ä¼æ¥­åã®å®Œå…¨ä¸€è‡´ + ãƒ‰ãƒ¡ã‚¤ãƒ³é™å®š"
            )
        ]
    
    async def run_query_test(self, 
                           spreadsheet_id: str,
                           sheet_name: str,
                           start_row: int = 2,
                           end_row: Optional[int] = None,
                           max_companies: int = 10) -> Dict[str, Any]:
        """
        ã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        
        Args:
            spreadsheet_id: ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆID
            sheet_name: ã‚·ãƒ¼ãƒˆå
            start_row: é–‹å§‹è¡Œ
            end_row: çµ‚äº†è¡Œ
            max_companies: æœ€å¤§å‡¦ç†ä¼æ¥­æ•°
        
        Returns:
            ãƒ†ã‚¹ãƒˆçµæœã®è©³ç´°
        """
        try:
            logger.info("=== ãƒ•ã‚§ãƒ¼ã‚º1 ã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
            
            # ä¼æ¥­ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            companies = await self._load_test_companies(
                spreadsheet_id, sheet_name, start_row, end_row, max_companies
            )
            
            if not companies:
                logger.error("ãƒ†ã‚¹ãƒˆå¯¾è±¡ä¼æ¥­ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return {"success": False, "error": "No companies found"}
            
            logger.info(f"ãƒ†ã‚¹ãƒˆå¯¾è±¡ä¼æ¥­: {len(companies)}ç¤¾")
            
            # å„ä¼æ¥­ã«å¯¾ã—ã¦ã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            test_results = []
            
            for i, company in enumerate(companies):
                logger.info(f"--- ä¼æ¥­ {i+1}/{len(companies)}: {company.company_name} ({company.id}) ---")
                
                company_result = await self._test_company_queries(company)
                test_results.append(company_result)
                
                # é©åº¦ãªé–“éš”ã‚’ç½®ã
                await asyncio.sleep(0.5)
            
            # çµæœã‚µãƒãƒªãƒ¼ç”Ÿæˆ
            summary = self._generate_test_summary(test_results)
            
            logger.info("=== ãƒ•ã‚§ãƒ¼ã‚º1 ã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆå®Œäº† ===")
            return {
                "success": True,
                "summary": summary,
                "detailed_results": test_results
            }
            
        except Exception as e:
            logger.error(f"ã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            logger.error(traceback.format_exc())
            return {"success": False, "error": str(e)}
    
    async def _load_test_companies(self, 
                                 spreadsheet_id: str,
                                 sheet_name: str,
                                 start_row: int,
                                 end_row: Optional[int],
                                 max_companies: int) -> List[CompanyInfo]:
        """ãƒ†ã‚¹ãƒˆå¯¾è±¡ä¼æ¥­ã®èª­ã¿è¾¼ã¿"""
        try:
            # ã‚·ãƒ¼ãƒˆè¨­å®šä½œæˆ
            google_sheets_config = self.config.get('google_sheets', {})
            sheet_config = SheetConfig(
                service_account_file=google_sheets_config.get('service_account_file'),
                spreadsheet_id=spreadsheet_id,
                sheet_name=sheet_name,
                input_columns=google_sheets_config.get('input_columns', {
                    'id': 'A',
                    'prefecture': 'B', 
                    'industry': 'C',
                    'company_name': 'D'
                }),
                start_row=start_row,
                end_row=end_row
            )
            
            # ä¼æ¥­ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            companies = self.data_loader.load_companies_from_range(sheet_config)
            
            # æœ€å¤§æ•°åˆ¶é™
            if len(companies) > max_companies:
                companies = companies[:max_companies]
                logger.info(f"ä¼æ¥­æ•°ã‚’{max_companies}ç¤¾ã«åˆ¶é™ã—ã¾ã—ãŸ")
            
            return companies
            
        except Exception as e:
            logger.error(f"ä¼æ¥­ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    async def _test_company_queries(self, company: CompanyInfo) -> Dict[str, Any]:
        """1ä¼æ¥­ã«å¯¾ã™ã‚‹å…¨ã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆ"""
        try:
            company_result = {
                "company": {
                    "id": company.id,
                    "name": company.company_name,
                    "prefecture": company.prefecture,
                    "industry": company.industry
                },
                "query_results": [],
                "best_overall": None
            }
            
            all_scored_urls = []
            
            # å„ã‚¯ã‚¨ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒ†ã‚¹ãƒˆ
            for pattern in self.query_patterns:
                logger.info(f"  ã‚¯ã‚¨ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern.name}")
                
                try:
                    # ã‚¯ã‚¨ãƒªç”Ÿæˆ
                    query_text = QueryGenerator.generate_custom_query(pattern.template, company)
                    logger.info(f"  ç”Ÿæˆã‚¯ã‚¨ãƒª: {query_text}")
                    
                    # æ¤œç´¢å®Ÿè¡Œ
                    search_results = self.brave_client.search(query_text)
                    
                    if not search_results:
                        logger.warning(f"  æ¤œç´¢çµæœãªã—: {pattern.name}")
                        company_result["query_results"].append({
                            "pattern": pattern._asdict(),
                            "query_text": query_text,
                            "search_results_count": 0,
                            "scored_urls": [],
                            "best_url": None,
                            "error": "No search results"
                        })
                        continue
                    
                    logger.info(f"  æ¤œç´¢çµæœ: {len(search_results)}ä»¶")
                    
                    # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°å®Ÿè¡Œï¼ˆéåŒæœŸå¯¾å¿œã®å ´åˆã¯é©åˆ‡ã«ä¿®æ­£ãŒå¿…è¦ï¼‰
                    scored_urls = []
                    for result in search_results:
                        scored = self.scorer.calculate_score(result, company, pattern.name)
                        if scored:
                            scored_urls.append(scored)
                    
                    # ãƒ™ã‚¹ãƒˆURLé¸æŠ
                    best_url = max(scored_urls, key=lambda x: x.total_score) if scored_urls else None
                    
                    # çµæœä¿å­˜
                    query_result = {
                        "pattern": pattern._asdict(),
                        "query_text": query_text,
                        "search_results_count": len(search_results),
                        "scored_urls": [self._serialize_hp_candidate(score) for score in scored_urls],
                        "best_url": self._serialize_hp_candidate(best_url) if best_url else None
                    }
                    
                    company_result["query_results"].append(query_result)
                    all_scored_urls.extend(scored_urls)
                    
                    # çµæœè¡¨ç¤º
                    self._display_query_result(pattern, query_text, search_results, scored_urls, best_url)
                    
                except Exception as e:
                    logger.error(f"  ã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ ({pattern.name}): {e}")
                    company_result["query_results"].append({
                        "pattern": pattern._asdict(),
                        "query_text": "",
                        "search_results_count": 0,
                        "scored_urls": [],
                        "best_url": None,
                        "error": str(e)
                    })
            
            # å…¨ã‚¯ã‚¨ãƒªä¸­ã®ãƒ™ã‚¹ãƒˆURL
            if all_scored_urls:
                best_overall = max(all_scored_urls, key=lambda x: x.total_score)
                company_result["best_overall"] = self._serialize_hp_candidate(best_overall)
                logger.info(f"  ğŸ† å…¨ã‚¯ã‚¨ãƒªä¸­ã®ãƒ™ã‚¹ãƒˆ: {best_overall.url} ({best_overall.total_score}ç‚¹)")
            
            return company_result
            
        except Exception as e:
            logger.error(f"ä¼æ¥­ã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {company.id} - {e}")
            return {
                "company": {
                    "id": company.id,
                    "name": company.company_name,
                    "prefecture": company.prefecture,
                    "industry": company.industry
                },
                "query_results": [],
                "best_overall": None,
                "error": str(e)
            }
    
    def _display_query_result(self, pattern, query_text, search_results, scored_urls, best_url):
        """ã‚¯ã‚¨ãƒªçµæœã®è¡¨ç¤º"""
        logger.info(f"    ç”Ÿæˆã‚¯ã‚¨ãƒª: {query_text}")
        logger.info(f"    æ¤œç´¢çµæœæ•°: {len(search_results)}")
        logger.info(f"    ã‚¹ã‚³ã‚¢è¨ˆç®—å¾Œ: {len(scored_urls)}")
        
        if best_url:
            logger.info(f"    ãƒ™ã‚¹ãƒˆURL: {best_url.url}")
            logger.info(f"    ã‚¹ã‚³ã‚¢: {best_url.total_score}ç‚¹ ({best_url.judgment})")
            logger.info(f"    ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸: {'Yes' if best_url.is_top_page else 'No'}")
            logger.info(f"    ãƒ‰ãƒ¡ã‚¤ãƒ³é¡ä¼¼åº¦: {best_url.domain_similarity:.1f}%")
            
            # ã‚¹ã‚³ã‚¢å†…è¨³è¡¨ç¤º
            if best_url.score_details:
                logger.info("    ã‚¹ã‚³ã‚¢å†…è¨³:")
                for component, score in best_url.score_details.items():
                    logger.info(f"      {component}: {score}")
        else:
            logger.warning("    æœ‰åŠ¹ãªURLãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    def _serialize_hp_candidate(self, candidate) -> Dict[str, Any]:
        """HPCandidateã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚º"""
        if not candidate:
            return None
        
        return {
            "url": candidate.url,
            "title": candidate.title,
            "description": candidate.description,
            "search_rank": candidate.search_rank,
            "query_pattern": candidate.query_pattern,
            "domain_similarity": candidate.domain_similarity,
            "is_top_page": candidate.is_top_page,
            "total_score": candidate.total_score,
            "judgment": candidate.judgment,
            "score_details": candidate.score_details
        }
    
    def _generate_test_summary(self, test_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        try:
            total_companies = len(test_results)
            successful_companies = len([r for r in test_results if "error" not in r])
            
            # ã‚¯ã‚¨ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥çµ±è¨ˆ
            pattern_stats = {}
            for pattern in self.query_patterns:
                pattern_name = pattern.name
                pattern_stats[pattern_name] = {
                    "total_searches": 0,
                    "successful_searches": 0,
                    "found_urls": 0,
                    "auto_adopt_count": 0,
                    "needs_review_count": 0,
                    "manual_check_count": 0
                }
            
            # å…¨ä½“çµ±è¨ˆ
            overall_stats = {
                "best_urls_found": 0,
                "auto_adopt_count": 0,
                "needs_review_count": 0,
                "manual_check_count": 0
            }
            
            # çµæœé›†è¨ˆ
            for result in test_results:
                if "error" in result:
                    continue
                
                # å…¨ä½“ãƒ™ã‚¹ãƒˆURLçµ±è¨ˆ
                if result.get("best_overall"):
                    overall_stats["best_urls_found"] += 1
                    judgment = result["best_overall"]["judgment"]
                    overall_stats[f"{self._judgment_to_key(judgment)}_count"] += 1
                
                # ã‚¯ã‚¨ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥çµ±è¨ˆ
                for query_result in result.get("query_results", []):
                    pattern_name = query_result["pattern"]["name"]
                    if pattern_name in pattern_stats:
                        stats = pattern_stats[pattern_name]
                        stats["total_searches"] += 1
                        
                        if "error" not in query_result:
                            stats["successful_searches"] += 1
                            stats["found_urls"] += len(query_result.get("scored_urls", []))
                            
                            if query_result.get("best_url"):
                                judgment = query_result["best_url"]["judgment"]
                                stats[f"{self._judgment_to_key(judgment)}_count"] += 1
            
            return {
                "total_companies": total_companies,
                "successful_companies": successful_companies,
                "success_rate": successful_companies / total_companies if total_companies > 0 else 0,
                "pattern_statistics": pattern_stats,
                "overall_statistics": overall_stats
            }
            
        except Exception as e:
            logger.error(f"ã‚µãƒãƒªãƒ¼ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}
    
    def _judgment_to_key(self, judgment: str) -> str:
        """åˆ¤å®šçµæœã‚’ã‚­ãƒ¼ã«å¤‰æ›"""
        mapping = {
            "è‡ªå‹•æ¡ç”¨": "auto_adopt",
            "è¦ç¢ºèª": "needs_review", 
            "æ‰‹å‹•ç¢ºèª": "manual_check"
        }
        return mapping.get(judgment, "unknown")
    
    def save_results_to_file(self, results: Dict[str, Any], output_file: str):
        """çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            logger.info(f"çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")
        except Exception as e:
            logger.error(f"çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    try:
        # è¨­å®šèª­ã¿è¾¼ã¿
        config_manager = ConfigManager()
        config = config_manager.load_config()
        
        # ãƒ•ã‚§ãƒ¼ã‚º1ãƒ†ã‚¹ã‚¿ãƒ¼åˆæœŸåŒ–
        tester = Phase1QueryTester(config)
        
        # ãƒ†ã‚¹ãƒˆè¨­å®šï¼ˆç’°å¢ƒã«åˆã‚ã›ã¦å¤‰æ›´ï¼‰
        spreadsheet_id = config.get('google_sheets', {}).get('input_spreadsheet_id', '')
        sheet_name = config.get('google_sheets', {}).get('input_sheet_name', 'Sheet1')
        
        if not spreadsheet_id:
            logger.error("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«input_spreadsheet_idãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return
        
        # ã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        results = await tester.run_query_test(
            spreadsheet_id=spreadsheet_id,
            sheet_name=sheet_name,
            start_row=2,
            end_row=11,  # 10ç¤¾ã§ãƒ†ã‚¹ãƒˆ
            max_companies=10
        )
        
        if results["success"]:
            logger.info("=== ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼ ===")
            summary = results["summary"]
            logger.info(f"å¯¾è±¡ä¼æ¥­æ•°: {summary['total_companies']}")
            logger.info(f"æˆåŠŸä¼æ¥­æ•°: {summary['successful_companies']}")
            logger.info(f"æˆåŠŸç‡: {summary['success_rate']:.1%}")
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥çµæœ
            for pattern_name, stats in summary["pattern_statistics"].items():
                logger.info(f"\n[{pattern_name}]")
                logger.info(f"  æ¤œç´¢å®Ÿè¡Œ: {stats['successful_searches']}/{stats['total_searches']}")
                logger.info(f"  URLç™ºè¦‹: {stats['found_urls']}ä»¶")
                logger.info(f"  è‡ªå‹•æ¡ç”¨: {stats['auto_adopt_count']}ä»¶")
                logger.info(f"  è¦ç¢ºèª: {stats['needs_review_count']}ä»¶")
                logger.info(f"  æ‰‹å‹•ç¢ºèª: {stats['manual_check_count']}ä»¶")
            
            # çµæœä¿å­˜
            import time
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_file = f"logs/phase1_query_test_results_{timestamp}.json"
            tester.save_results_to_file(results, output_file)
        else:
            logger.error(f"ãƒ†ã‚¹ãƒˆå¤±æ•—: {results.get('error')}")
    
    except Exception as e:
        logger.error(f"ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    asyncio.run(main()) 